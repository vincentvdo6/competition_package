{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Expand Seed Pool + Per-Target Swap Discovery\n",
    "\n",
    "Trains new vanilla GRU seeds (configurable range) on Colab GPU, caches their validation\n",
    "predictions, then discovers the best 2-slot per-target swap candidates and builds ONNX\n",
    "submission zips.\n",
    "\n",
    "**Required mirror layout (Google Drive):**\n",
    "- `wunderfund_mirror/train.parquet`\n",
    "- `wunderfund_mirror/valid.parquet`\n",
    "- `wunderfund_mirror/vanilla_all/gru_parity_v1_seed42.pt` ... `seed64.pt`\n",
    "\n",
    "**Workflow:** Run cells 1-9 in order. Cell 2 (Config) is the only one to edit between sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from pathlib import Path\n",
    "import os, shutil, subprocess, sys, re, time, json\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "print('Drive mounted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# CONFIG  -  only cell you need to edit between sessions\n",
    "# =============================================================\n",
    "\n",
    "REPO_URL = 'https://github.com/vincentvdo6/competition_package.git'\n",
    "BRANCH   = 'master'\n",
    "REPO     = Path('/content/competition_package')\n",
    "MIRROR   = Path('/content/drive/MyDrive/wunderfund_mirror')\n",
    "\n",
    "# Seeds already trained and stored in mirror\n",
    "EXISTING_SEEDS = list(range(42, 65))          # 23 seeds: 42-64\n",
    "\n",
    "# New seeds to train this session (set to [] to skip training)\n",
    "NEW_SEEDS = list(range(65, 85))               # 20 new seeds: 65-84\n",
    "\n",
    "ALL_SEEDS = EXISTING_SEEDS + NEW_SEEDS\n",
    "\n",
    "# Current best anchor ensemble (per-target weights)\n",
    "ANCHOR_SEEDS = [43, 44, 45, 46, 50, 54, 55, 57, 58, 59, 60, 61, 63, 64]\n",
    "ANCHOR_W0    = [1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0]             # t0 weights\n",
    "ANCHOR_W1    = [1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0.25, 0, 1.75]       # t1 weights\n",
    "\n",
    "# Session tag used in output file names\n",
    "SESSION_TAG  = 'feb22-b1'\n",
    "SLOT_A_NAME  = f'{SESSION_TAG}-t1swap-a-onnx.zip'\n",
    "SLOT_B_NAME  = f'{SESSION_TAG}-t0swap-b-onnx.zip'\n",
    "\n",
    "# Cache and discovery settings\n",
    "CACHE_DIR    = 'cache/all_seeds_valid_preds'\n",
    "REPORT_PATH  = f'logs/parity_swap_discovery_{SESSION_TAG}.json'\n",
    "BOOTSTRAP    = 200\n",
    "DELTA_MIN    = 0.00015\n",
    "P10_MAX_DROP = 0.00005\n",
    "\n",
    "print(f'Existing seeds : {len(EXISTING_SEEDS)} ({EXISTING_SEEDS[0]}-{EXISTING_SEEDS[-1]})')\n",
    "print(f'New seeds      : {len(NEW_SEEDS)} ({NEW_SEEDS[0] if NEW_SEEDS else \"none\"}-{NEW_SEEDS[-1] if NEW_SEEDS else \"none\"})')\n",
    "print(f'Total pool     : {len(ALL_SEEDS)} seeds')\n",
    "print(f'Session        : {SESSION_TAG}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone / refresh repo\n",
    "if REPO.exists():\n",
    "    shutil.rmtree(REPO)\n",
    "\n",
    "subprocess.run(['git', 'clone', '--branch', BRANCH, REPO_URL, str(REPO)], check=True)\n",
    "os.chdir(REPO)\n",
    "subprocess.run(['git', 'pull', 'origin', BRANCH], check=True)\n",
    "\n",
    "for script in [\n",
    "    'scripts/train.py',\n",
    "    'scripts/greedy_vanilla_ensemble.py',\n",
    "    'scripts/discover_parity_swaps.py',\n",
    "    'scripts/check_submission_zip.py',\n",
    "]:\n",
    "    assert (REPO / script).exists(), f'Missing script: {script}'\n",
    "\n",
    "print('Repo ready:', REPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4-copy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy datasets and existing checkpoints from mirror\n",
    "(REPO / 'datasets').mkdir(parents=True, exist_ok=True)\n",
    "(REPO / 'logs' / 'vanilla_all').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Datasets\n",
    "for fname in ['train.parquet', 'valid.parquet']:\n",
    "    src = MIRROR / fname\n",
    "    assert src.exists(), f'Missing from mirror: {src}'\n",
    "    shutil.copy2(src, REPO / 'datasets' / fname)\n",
    "    print(f'Copied {fname}')\n",
    "\n",
    "# Existing checkpoints\n",
    "ckpt_mirror = MIRROR / 'vanilla_all'\n",
    "ckpt_local  = REPO / 'logs' / 'vanilla_all'\n",
    "n_copied = 0\n",
    "for seed in EXISTING_SEEDS:\n",
    "    src = ckpt_mirror / f'gru_parity_v1_seed{seed}.pt'\n",
    "    if src.exists():\n",
    "        shutil.copy2(src, ckpt_local / src.name)\n",
    "        n_copied += 1\n",
    "    else:\n",
    "        print(f'  WARN: missing existing checkpoint seed{seed} in mirror')\n",
    "\n",
    "print(f'Copied {n_copied}/{len(EXISTING_SEEDS)} existing checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train new seeds  (skips any seed already in local logs/ or mirror)\n",
    "ckpt_mirror = MIRROR / 'vanilla_all'\n",
    "ckpt_mirror.mkdir(parents=True, exist_ok=True)\n",
    "ckpt_local  = REPO / 'logs' / 'vanilla_all'\n",
    "\n",
    "skipped, trained, failed = [], [], []\n",
    "\n",
    "for seed in NEW_SEEDS:\n",
    "    ckpt_name   = f'gru_parity_v1_seed{seed}.pt'\n",
    "    local_ckpt  = ckpt_local  / ckpt_name\n",
    "    mirror_ckpt = ckpt_mirror / ckpt_name\n",
    "\n",
    "    if local_ckpt.exists():\n",
    "        print(f'seed{seed}: already local -- skip')\n",
    "        skipped.append(seed)\n",
    "        continue\n",
    "    if mirror_ckpt.exists():\n",
    "        shutil.copy2(mirror_ckpt, local_ckpt)\n",
    "        print(f'seed{seed}: found in mirror -- copied')\n",
    "        skipped.append(seed)\n",
    "        continue\n",
    "\n",
    "    print(f'\\n{\"=\"*60}\\nTraining seed {seed} ...\\n{\"=\"*60}')\n",
    "    t_start = time.time()\n",
    "    cmd = [\n",
    "        sys.executable, '-u', 'scripts/train.py',\n",
    "        '--config', 'configs/gru_parity_v1.yaml',\n",
    "        '--seed', str(seed),\n",
    "    ]\n",
    "    proc = subprocess.Popen(\n",
    "        cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1\n",
    "    )\n",
    "    for line in proc.stdout:\n",
    "        print(line, end='', flush=True)\n",
    "    rc = proc.wait()\n",
    "    elapsed = time.time() - t_start\n",
    "\n",
    "    if rc != 0:\n",
    "        print(f'  ERROR: seed{seed} failed (exit {rc})')\n",
    "        failed.append(seed)\n",
    "        continue\n",
    "\n",
    "    if local_ckpt.exists():\n",
    "        shutil.copy2(local_ckpt, mirror_ckpt)\n",
    "        print(f'  Saved to mirror [{elapsed:.0f}s]')\n",
    "        trained.append(seed)\n",
    "    else:\n",
    "        print(f'  WARN: checkpoint not found after training: {local_ckpt}')\n",
    "        failed.append(seed)\n",
    "\n",
    "print(f'\\nSummary: skipped={len(skipped)}, trained={len(trained)}, failed={len(failed)}')\n",
    "if failed:\n",
    "    print(f'Failed seeds: {failed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache validation predictions for all available checkpoints\n",
    "all_ckpts = sorted((REPO / 'logs' / 'vanilla_all').glob('gru_parity_v1_seed*.pt'))\n",
    "print(f'Found {len(all_ckpts)} checkpoints to cache')\n",
    "\n",
    "cmd = [\n",
    "    sys.executable, 'scripts/greedy_vanilla_ensemble.py', 'cache',\n",
    "    '--checkpoints', *[str(c) for c in all_ckpts],\n",
    "    '--data', 'datasets/valid.parquet',\n",
    "    '--cache-dir', CACHE_DIR,\n",
    "]\n",
    "proc = subprocess.Popen(\n",
    "    cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1\n",
    ")\n",
    "for line in proc.stdout:\n",
    "    print(line, end='', flush=True)\n",
    "rc = proc.wait()\n",
    "print(f'\\nCache exit code: {rc}')\n",
    "assert rc == 0, 'Cache step failed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7-discover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap discovery: LOO + candidate swaps + bootstrap delta + build ONNX zips\n",
    "\n",
    "# Determine which seeds were actually cached (handles any training failures)\n",
    "cache_path = REPO / CACHE_DIR\n",
    "cached_seeds = sorted(\n",
    "    int(re.search(r'seed(\\d+)', f.stem).group(1))\n",
    "    for f in cache_path.glob('gru_parity_v1_seed*.npz')\n",
    ")\n",
    "print(f'Cached seeds ({len(cached_seeds)}): {cached_seeds}')\n",
    "\n",
    "# Verify all anchor seeds are present in cache\n",
    "missing_anchor = [s for s in ANCHOR_SEEDS if s not in cached_seeds]\n",
    "assert not missing_anchor, f'Anchor seeds missing from cache: {missing_anchor}'\n",
    "\n",
    "cmd = [\n",
    "    sys.executable, 'scripts/discover_parity_swaps.py',\n",
    "    '--cache-dir',      CACHE_DIR,\n",
    "    '--data',           'datasets/valid.parquet',\n",
    "    '--required-seeds', *[str(s) for s in cached_seeds],\n",
    "    '--anchor-seeds',   *[str(s) for s in ANCHOR_SEEDS],\n",
    "    '--anchor-w0',      *[str(w) for w in ANCHOR_W0],\n",
    "    '--anchor-w1',      *[str(w) for w in ANCHOR_W1],\n",
    "    '--delta-min',      str(DELTA_MIN),\n",
    "    '--p10-max-drop',   str(P10_MAX_DROP),\n",
    "    '--bootstrap',      str(BOOTSTRAP),\n",
    "    '--output-report',  REPORT_PATH,\n",
    "    '--output-dir',     'submissions/ready',\n",
    "    '--slot-a-name',    SLOT_A_NAME,\n",
    "    '--slot-b-name',    SLOT_B_NAME,\n",
    "]\n",
    "proc = subprocess.Popen(\n",
    "    cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1\n",
    ")\n",
    "for line in proc.stdout:\n",
    "    print(line, end='', flush=True)\n",
    "rc = proc.wait()\n",
    "print(f'\\nDiscovery exit code: {rc}')\n",
    "assert rc == 0, 'Swap discovery failed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8-checkzips",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify built submission zips\n",
    "import glob as _glob\n",
    "\n",
    "zips = sorted(_glob.glob(f'submissions/ready/{SESSION_TAG}-*.zip'))\n",
    "assert zips, f'No zips found for session {SESSION_TAG}'\n",
    "\n",
    "for z in zips:\n",
    "    print(f'\\n=== {z} ===')\n",
    "    subprocess.run([sys.executable, 'scripts/check_submission_zip.py', z], check=True)\n",
    "\n",
    "print(f'\\nArtifacts:')\n",
    "print(f'  Report : {REPORT_PATH}')\n",
    "for z in zips:\n",
    "    print(f'  Zip    : {z}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View discovery report summary\n",
    "report_file = REPO / REPORT_PATH\n",
    "assert report_file.exists(), f'Report not found: {report_file}'\n",
    "report = json.loads(report_file.read_text())\n",
    "\n",
    "anchor_sc = report['anchor']['score']\n",
    "print(f'ANCHOR  avg={anchor_sc[\"avg\"]:.4f}  t0={anchor_sc[\"t0\"]:.4f}  t1={anchor_sc[\"t1\"]:.4f}')\n",
    "print(f'  seeds={report[\"anchor\"][\"seeds\"]}')\n",
    "print()\n",
    "\n",
    "print('TOP 15 SINGLE SEEDS (by avg val score):')\n",
    "print(f'{\"Seed\":>6}  {\"avg\":>8}  {\"t0\":>8}  {\"t1\":>8}')\n",
    "print('-' * 38)\n",
    "for row in sorted(report['single_seed_ranking'], key=lambda r: -r['avg'])[:15]:\n",
    "    marker = ' *' if row['seed'] in report['anchor']['seeds'] else ''\n",
    "    print(f'  {row[\"seed\"]:>4}   {row[\"avg\"]:>8.4f}  {row[\"t0\"]:>8.4f}  {row[\"t1\"]:>8.4f}{marker}')\n",
    "print('  (* = in anchor)')\n",
    "print()\n",
    "\n",
    "def show_slot(label, slot, zip_name):\n",
    "    boot = slot['bootstrap_delta_vs_anchor']\n",
    "    gate = 'PASS' if slot['keep_gate'] else 'FAIL'\n",
    "    print(f'{label}:')\n",
    "    print(f'  Replace seed {slot[\"replace_seed\"]} -> candidate seed {slot[\"candidate_seed\"]}')\n",
    "    print(f'  delta_avg={slot[\"delta_avg\"]:+.5f}  delta_t0={slot[\"delta_t0\"]:+.5f}  delta_t1={slot[\"delta_t1\"]:+.5f}')\n",
    "    print(f'  bootstrap  mean={boot[\"mean\"]:+.5f}  p10={boot[\"p10\"]:+.5f}  p50={boot[\"p50\"]:+.5f}  gate={gate}')\n",
    "    print(f'  zip: submissions/ready/{zip_name}')\n",
    "\n",
    "show_slot('SLOT A (t1 swap)', report['selected']['slot_a_t1'], SLOT_A_NAME)\n",
    "print()\n",
    "show_slot('SLOT B (t0 swap)', report['selected']['slot_b_t0'], SLOT_B_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
