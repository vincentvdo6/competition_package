{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Setup â€” clone repo, link data\n",
    "import os, subprocess\n",
    "REPO = \"/kaggle/working/competition_package\"\n",
    "os.chdir(\"/kaggle/working\")\n",
    "os.system(f\"rm -rf {REPO}\")\n",
    "os.system(f\"git clone https://github.com/vincentvdo6/competition_package.git {REPO}\")\n",
    "os.chdir(REPO)\n",
    "os.makedirs(\"datasets\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "os.system(\"ln -sf /kaggle/input/wunderfund-predictorium/train.parquet datasets/train.parquet\")\n",
    "os.system(\"ln -sf /kaggle/input/wunderfund-predictorium/valid.parquet datasets/valid.parquet\")\n",
    "print(\"Commit:\", subprocess.check_output([\"git\", \"rev-parse\", \"--short\", \"HEAD\"], text=True).strip())\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tw2-batch1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: tightwd_v2 seeds 54-63 (10 seeds, ~16 min)\n",
    "# Existing tw2: 42-53 (12 seeds). This adds 10 more.\n",
    "import os\n",
    "os.chdir(\"/kaggle/working/competition_package\")\n",
    "for seed in range(54, 64):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training gru_derived_tightwd_v2 seed {seed}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    os.system(\n",
    "        f\"python -u scripts/train.py \"\n",
    "        f\"--config configs/gru_derived_tightwd_v2.yaml \"\n",
    "        f\"--seed {seed} --device cuda\"\n",
    "    )\n",
    "print(\"\\nBatch 1 done: tw2 seeds 54-63\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tw2-batch2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: tightwd_v2 seeds 64-73 (10 seeds, ~16 min)\n",
    "import os\n",
    "os.chdir(\"/kaggle/working/competition_package\")\n",
    "for seed in range(64, 74):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training gru_derived_tightwd_v2 seed {seed}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    os.system(\n",
    "        f\"python -u scripts/train.py \"\n",
    "        f\"--config configs/gru_derived_tightwd_v2.yaml \"\n",
    "        f\"--seed {seed} --device cuda\"\n",
    "    )\n",
    "print(\"\\nBatch 2 done: tw2 seeds 64-73\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p1-batch1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: pearson_v1 seeds 51-60 (10 seeds, ~16 min)\n",
    "# Existing p1: 42-50 (9 seeds). This adds 10 more.\n",
    "import os\n",
    "os.chdir(\"/kaggle/working/competition_package\")\n",
    "for seed in range(51, 61):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training gru_pearson_v1 seed {seed}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    os.system(\n",
    "        f\"python -u scripts/train.py \"\n",
    "        f\"--config configs/gru_pearson_v1.yaml \"\n",
    "        f\"--seed {seed} --device cuda\"\n",
    "    )\n",
    "print(\"\\nBatch 3 done: p1 seeds 51-60\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p1-batch2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: pearson_v1 seeds 61-70 (10 seeds, ~16 min)\n",
    "import os\n",
    "os.chdir(\"/kaggle/working/competition_package\")\n",
    "for seed in range(61, 71):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training gru_pearson_v1 seed {seed}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    os.system(\n",
    "        f\"python -u scripts/train.py \"\n",
    "        f\"--config configs/gru_pearson_v1.yaml \"\n",
    "        f\"--seed {seed} --device cuda\"\n",
    "    )\n",
    "print(\"\\nBatch 4 done: p1 seeds 61-70\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strip-zip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Strip checkpoints (remove optimizer state) + copy normalizers + zip\n",
    "import os, torch, glob, shutil\n",
    "os.chdir(\"/kaggle/working/competition_package\")\n",
    "os.makedirs(\"logs/slim\", exist_ok=True)\n",
    "\n",
    "for pt in sorted(glob.glob(\"logs/*.pt\")):\n",
    "    try:\n",
    "        ckpt = torch.load(pt, map_location=\"cpu\", weights_only=False)\n",
    "    except TypeError:\n",
    "        ckpt = torch.load(pt, map_location=\"cpu\")\n",
    "    slim = {\n",
    "        \"model_state_dict\": ckpt[\"model_state_dict\"],\n",
    "        \"config\": ckpt.get(\"config\", {}),\n",
    "        \"best_score\": ckpt.get(\"best_score\", None),\n",
    "    }\n",
    "    out = f\"logs/slim/{os.path.basename(pt)}\"\n",
    "    torch.save(slim, out)\n",
    "    orig = os.path.getsize(pt) / 1e6\n",
    "    new = os.path.getsize(out) / 1e6\n",
    "    print(f\"{os.path.basename(pt)}: {orig:.1f}MB -> {new:.1f}MB\")\n",
    "\n",
    "for npz in sorted(glob.glob(\"logs/normalizer_*.npz\")):\n",
    "    shutil.copy(npz, f\"logs/slim/{os.path.basename(npz)}\")\n",
    "    print(f\"Copied {os.path.basename(npz)}\")\n",
    "\n",
    "print(f\"\\n--- logs/slim/ contents ({len(os.listdir('logs/slim'))} files) ---\")\n",
    "for f in sorted(os.listdir(\"logs/slim\")):\n",
    "    sz = os.path.getsize(f\"logs/slim/{f}\") / 1e6\n",
    "    print(f\"  {f}: {sz:.1f}MB\")\n",
    "\n",
    "# Zip for download\n",
    "shutil.make_archive(\"/kaggle/working/gru_expansion_v2\", \"zip\",\n",
    "                     \"/kaggle/working/competition_package/logs/slim\")\n",
    "sz = os.path.getsize(\"/kaggle/working/gru_expansion_v2.zip\") / 1e6\n",
    "print(f\"\\ngru_expansion_v2.zip: {sz:.1f}MB\")\n",
    "print(\"Download from: /kaggle/working/gru_expansion_v2.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "val-scores",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Print validation scores (sorted best to worst)\n",
    "import os, glob, torch\n",
    "os.chdir(\"/kaggle/working/competition_package\")\n",
    "\n",
    "results = []\n",
    "for pt in sorted(glob.glob(\"logs/*.pt\")):\n",
    "    try:\n",
    "        ckpt = torch.load(pt, map_location=\"cpu\", weights_only=False)\n",
    "    except TypeError:\n",
    "        ckpt = torch.load(pt, map_location=\"cpu\")\n",
    "    score = ckpt.get(\"best_score\", ckpt.get(\"val_score\", None))\n",
    "    name = os.path.basename(pt)\n",
    "    if isinstance(score, (int, float)):\n",
    "        results.append((name, float(score)))\n",
    "    else:\n",
    "        results.append((name, 0.0))\n",
    "\n",
    "# Sort by score descending\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"{'Rank':<5} {'Model':<55} {'Val Score':>10}\")\n",
    "print(\"-\" * 72)\n",
    "for i, (name, score) in enumerate(results, 1):\n",
    "    marker = \" *\" if score >= 0.264 else \"\"\n",
    "    print(f\"{i:<5} {name:<55} {score:>10.4f}{marker}\")\n",
    "\n",
    "# Summary stats per config\n",
    "tw2 = [(n, s) for n, s in results if \"tightwd\" in n]\n",
    "p1 = [(n, s) for n, s in results if \"pearson\" in n]\n",
    "print(f\"\\n--- tightwd_v2: {len(tw2)} seeds ---\")\n",
    "if tw2:\n",
    "    scores = [s for _, s in tw2]\n",
    "    print(f\"  Best 5: {sorted(scores, reverse=True)[:5]}\")\n",
    "    print(f\"  Mean: {sum(scores)/len(scores):.4f}, Std: {(sum((s-sum(scores)/len(scores))**2 for s in scores)/len(scores))**0.5:.4f}\")\n",
    "print(f\"\\n--- pearson_v1: {len(p1)} seeds ---\")\n",
    "if p1:\n",
    "    scores = [s for _, s in p1]\n",
    "    print(f\"  Best 5: {sorted(scores, reverse=True)[:5]}\")\n",
    "    print(f\"  Mean: {sum(scores)/len(scores):.4f}, Std: {(sum((s-sum(scores)/len(scores))**2 for s in scores)/len(scores))**0.5:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
