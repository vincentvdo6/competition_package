{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Mount Drive, download data from Kaggle\n",
    "import os, json\n",
    "\n",
    "# Mount Drive for saving outputs\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "os.makedirs('/content/drive/MyDrive/wunderfund', exist_ok=True)\n",
    "\n",
    "# Install pinned kaggle + set credentials\n",
    "!pip install -q kaggle==1.6.14 --force-reinstall\n",
    "os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
    "    json.dump({\"username\": \"vincentvdo6\", \"key\": \"KGAT_17c43012d9e77edf2c183a25acb1489b\"}, f)\n",
    "os.chmod('/root/.kaggle/kaggle.json', 0o600)\n",
    "\n",
    "# Download + unzip dataset\n",
    "os.makedirs('/content/data', exist_ok=True)\n",
    "!kaggle datasets download -d vincentvdo6/wunderfund-predictorium -p /content/data/ --force\n",
    "!unzip -o -q /content/data/wunderfund-predictorium.zip -d /content/data/\n",
    "!ls /content/data/*.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup — clone repo, link data\n",
    "import os, subprocess\n",
    "REPO = \"/content/competition_package\"\n",
    "\n",
    "os.chdir(\"/content\")\n",
    "os.system(f\"rm -rf {REPO}\")\n",
    "os.system(f\"git clone https://github.com/vincentvdo6/competition_package.git {REPO}\")\n",
    "os.chdir(REPO)\n",
    "os.makedirs(\"datasets\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "# Link data from Kaggle download\n",
    "os.system('ln -sf /content/data/train.parquet datasets/train.parquet')\n",
    "os.system('ln -sf /content/data/valid.parquet datasets/valid.parquet')\n",
    "\n",
    "# Verify\n",
    "assert os.path.exists(\"datasets/train.parquet\"), \"train.parquet not found!\"\n",
    "assert os.path.exists(\"datasets/valid.parquet\"), \"valid.parquet not found!\"\n",
    "print(\"Commit:\", subprocess.check_output([\"git\", \"rev-parse\", \"--short\", \"HEAD\"], text=True).strip())\n",
    "print(f\"GPU: {os.popen('nvidia-smi --query-gpu=name --format=csv,noheader').read().strip()}\")\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Train baseline_match × 3 seeds (FOUNDATION — must run first)\n",
    "# Architecture: h=64, 3 layers, 32 raw features, linear output\n",
    "# Matches official baseline that scored 0.2761 LB\n",
    "# Expected: ~5 min per seed\n",
    "import os, subprocess\n",
    "os.chdir(\"/content/competition_package\")\n",
    "\n",
    "configs = [\n",
    "    ('gru_baseline_match_v1', 'configs/gru_baseline_match_v1.yaml'),\n",
    "]\n",
    "\n",
    "for config_name, config_path in configs:\n",
    "    for seed in [42, 43, 44]:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f'Training {config_name} seed {seed}')\n",
    "        print(f\"{'='*60}\", flush=True)\n",
    "        p = subprocess.Popen(\n",
    "            ['python', '-u', 'scripts/train.py',\n",
    "             '--config', config_path,\n",
    "             '--seed', str(seed), '--device', 'cuda'],\n",
    "            stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
    "            text=True, bufsize=1\n",
    "        )\n",
    "        for line in p.stdout:\n",
    "            print(line, end='')\n",
    "        rc = p.wait()\n",
    "        if rc != 0:\n",
    "            print(f'ERROR: seed {seed} failed with exit code {rc}')\n",
    "\n",
    "print('\\nBaseline match training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Train chrono init × 3 seeds\n",
    "# Change vs baseline_match: chrono initialization for GRU update gate\n",
    "import os, subprocess\n",
    "os.chdir(\"/content/competition_package\")\n",
    "\n",
    "for seed in [42, 43, 44]:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f'Training gru_v2_chrono seed {seed}')\n",
    "    print(f\"{'='*60}\", flush=True)\n",
    "    p = subprocess.Popen(\n",
    "        ['python', '-u', 'scripts/train.py',\n",
    "         '--config', 'configs/gru_v2_chrono.yaml',\n",
    "         '--seed', str(seed), '--device', 'cuda'],\n",
    "        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
    "        text=True, bufsize=1\n",
    "    )\n",
    "    for line in p.stdout:\n",
    "        print(line, end='')\n",
    "    rc = p.wait()\n",
    "    if rc != 0:\n",
    "        print(f'ERROR: seed {seed} failed with exit code {rc}')\n",
    "\n",
    "print('\\nChrono training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Train augmentation × 3 seeds\n",
    "# Change vs baseline_match: variance stretch/compress augmentation\n",
    "import os, subprocess\n",
    "os.chdir(\"/content/competition_package\")\n",
    "\n",
    "for seed in [42, 43, 44]:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f'Training gru_v2_aug seed {seed}')\n",
    "    print(f\"{'='*60}\", flush=True)\n",
    "    p = subprocess.Popen(\n",
    "        ['python', '-u', 'scripts/train.py',\n",
    "         '--config', 'configs/gru_v2_aug.yaml',\n",
    "         '--seed', str(seed), '--device', 'cuda'],\n",
    "        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
    "        text=True, bufsize=1\n",
    "    )\n",
    "    for line in p.stdout:\n",
    "        print(line, end='')\n",
    "    rc = p.wait()\n",
    "    if rc != 0:\n",
    "        print(f'ERROR: seed {seed} failed with exit code {rc}')\n",
    "\n",
    "print('\\nAugmentation training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Train SWA × 3 seeds\n",
    "# Change vs baseline_match: SWA after epoch 30 (constant LR + weight averaging)\n",
    "import os, subprocess\n",
    "os.chdir(\"/content/competition_package\")\n",
    "\n",
    "for seed in [42, 43, 44]:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f'Training gru_v2_swa seed {seed}')\n",
    "    print(f\"{'='*60}\", flush=True)\n",
    "    p = subprocess.Popen(\n",
    "        ['python', '-u', 'scripts/train.py',\n",
    "         '--config', 'configs/gru_v2_swa.yaml',\n",
    "         '--seed', str(seed), '--device', 'cuda'],\n",
    "        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
    "        text=True, bufsize=1\n",
    "    )\n",
    "    for line in p.stdout:\n",
    "        print(line, end='')\n",
    "    rc = p.wait()\n",
    "    if rc != 0:\n",
    "        print(f'ERROR: seed {seed} failed with exit code {rc}')\n",
    "\n",
    "print('\\nSWA training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Evaluate ALL configs — kill test comparison\n",
    "# Baseline match is the CONTROL. Chrono/aug/SWA are treatments.\n",
    "# Kill test: pass if treatment mean val > baseline_match mean val + 0.0010\n",
    "# Also: baseline_match must beat our old p1 mean (0.2627) to validate the arch change.\n",
    "import os, torch, glob\n",
    "os.chdir(\"/content/competition_package\")\n",
    "\n",
    "configs_to_eval = [\n",
    "    ('baseline_match', 'gru_baseline_match_v1'),\n",
    "    ('chrono', 'gru_v2_chrono'),\n",
    "    ('augmentation', 'gru_v2_aug'),\n",
    "    ('swa', 'gru_v2_swa'),\n",
    "]\n",
    "\n",
    "all_results = {}\n",
    "for label, prefix in configs_to_eval:\n",
    "    print(f'\\n--- {label} ({prefix}) ---')\n",
    "    scores = []\n",
    "    details = []\n",
    "    for pt in sorted(glob.glob(f'logs/{prefix}_seed*.pt')):\n",
    "        if '_epoch' in pt:\n",
    "            continue\n",
    "        ckpt = torch.load(pt, map_location='cpu', weights_only=False)\n",
    "        score = float(ckpt.get('best_score', 0.0))\n",
    "        epoch = ckpt.get('best_epoch', 0)\n",
    "        name = os.path.basename(pt)\n",
    "        scores.append(score)\n",
    "        details.append((name, score, epoch))\n",
    "        print(f'  {name}: val={score:.4f} (best epoch {epoch})')\n",
    "    if scores:\n",
    "        mean_score = sum(scores) / len(scores)\n",
    "        print(f'  Mean: {mean_score:.4f}, Min: {min(scores):.4f}, Max: {max(scores):.4f}')\n",
    "        all_results[label] = {'scores': scores, 'mean': mean_score, 'details': details}\n",
    "    else:\n",
    "        print('  No checkpoints found!')\n",
    "        all_results[label] = {'scores': [], 'mean': 0, 'details': []}\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print('KILL TEST SUMMARY')\n",
    "print(f\"{'='*60}\")\n",
    "print(f'Old p1 control mean: 0.2627')\n",
    "print()\n",
    "\n",
    "bm = all_results.get('baseline_match', {})\n",
    "bm_mean = bm.get('mean', 0)\n",
    "print(f'baseline_match mean: {bm_mean:.4f}')\n",
    "if bm_mean >= 0.2650:\n",
    "    print(f'  ARCH CHANGE PASS! {bm_mean:.4f} >= 0.2650 (above p1 + 0.0023)')\n",
    "elif bm_mean >= 0.2627:\n",
    "    print(f'  MARGINAL: {bm_mean:.4f} >= 0.2627 but < 0.2650')\n",
    "else:\n",
    "    print(f'  ARCH CHANGE FAIL: {bm_mean:.4f} < 0.2627 (worse than old p1)')\n",
    "print()\n",
    "\n",
    "for label in ['chrono', 'augmentation', 'swa']:\n",
    "    r = all_results.get(label, {})\n",
    "    r_mean = r.get('mean', 0)\n",
    "    delta = r_mean - bm_mean\n",
    "    r_scores = r.get('scores', [])\n",
    "    n_positive = sum(1 for s, bm_s in zip(r_scores, bm.get('scores', []))\n",
    "                     if s > bm_s) if r_scores and bm.get('scores') else 0\n",
    "    print(f'{label}: mean={r_mean:.4f}, delta={delta:+.4f}, positive={n_positive}/{len(r_scores)}')\n",
    "    if delta >= 0.0010 and n_positive >= 2:\n",
    "        print(f'  PASS! Meaningful improvement over baseline_match')\n",
    "    elif delta > 0:\n",
    "        print(f'  MARGINAL: Positive but not significant')\n",
    "    else:\n",
    "        print(f'  FAIL: No improvement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Training curves for all configs\n",
    "import json, glob, os\n",
    "os.chdir(\"/content/competition_package\")\n",
    "\n",
    "for prefix_label in ['gru_baseline_match_v1', 'gru_v2_chrono', 'gru_v2_aug', 'gru_v2_swa']:\n",
    "    print(f'\\n--- {prefix_label} ---')\n",
    "    for hist_file in sorted(glob.glob(f'logs/training_history_{prefix_label}*.json')):\n",
    "        with open(hist_file) as f:\n",
    "            hist = json.load(f)\n",
    "        name = os.path.basename(hist_file).replace('training_history_', '').replace('.json', '')\n",
    "        scores = [s['avg'] for s in hist['val_scores']]\n",
    "        t0_scores = [s['t0'] for s in hist['val_scores']]\n",
    "        t1_scores = [s['t1'] for s in hist['val_scores']]\n",
    "        best_idx = scores.index(max(scores))\n",
    "        print(f'  {name}:')\n",
    "        print(f'    Epochs: {len(scores)}, Best avg: {max(scores):.4f} at epoch {best_idx+1}')\n",
    "        print(f'    Best t0: {t0_scores[best_idx]:.4f}, Best t1: {t1_scores[best_idx]:.4f}')\n",
    "        print(f'    t0/t1 ratio: {t0_scores[best_idx]/max(t1_scores[best_idx], 1e-8):.2f}')\n",
    "        print(f'    Last 5 avg: {[\"{:.4f}\".format(s) for s in scores[-5:]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Strip checkpoints + zip + save to Drive\n",
    "# Run AFTER reviewing kill test results\n",
    "import os, torch, glob, shutil\n",
    "os.chdir(\"/content/competition_package\")\n",
    "os.makedirs('logs/slim', exist_ok=True)\n",
    "\n",
    "prefixes = ['gru_baseline_match_v1', 'gru_v2_chrono', 'gru_v2_aug', 'gru_v2_swa']\n",
    "for prefix in prefixes:\n",
    "    for pt in sorted(glob.glob(f'logs/{prefix}_*.pt')):\n",
    "        if '_epoch' in pt:\n",
    "            continue\n",
    "        ckpt = torch.load(pt, map_location='cpu', weights_only=False)\n",
    "        slim = {\n",
    "            'model_state_dict': ckpt['model_state_dict'],\n",
    "            'config': ckpt.get('config', {}),\n",
    "            'best_score': ckpt.get('best_score', None),\n",
    "        }\n",
    "        out = f'logs/slim/{os.path.basename(pt)}'\n",
    "        torch.save(slim, out)\n",
    "        orig = os.path.getsize(pt) / 1e6\n",
    "        new = os.path.getsize(out) / 1e6\n",
    "        print(f'{os.path.basename(pt)}: {orig:.1f}MB -> {new:.1f}MB')\n",
    "    # Copy normalizers\n",
    "    for npz in sorted(glob.glob(f'logs/normalizer_{prefix}*.npz')):\n",
    "        shutil.copy(npz, f'logs/slim/{os.path.basename(npz)}')\n",
    "        print(f'Copied {os.path.basename(npz)}')\n",
    "\n",
    "print(f'\\n--- logs/slim/ contents ({len(os.listdir(\"logs/slim\"))} files) ---')\n",
    "total_mb = 0\n",
    "for f in sorted(os.listdir('logs/slim')):\n",
    "    sz = os.path.getsize(f'logs/slim/{f}') / 1e6\n",
    "    total_mb += sz\n",
    "    print(f'  {f}: {sz:.1f}MB')\n",
    "print(f'  Total: {total_mb:.1f}MB')\n",
    "\n",
    "# Zip for download\n",
    "shutil.make_archive('/content/baseline_match_kill_test', 'zip',\n",
    "                    '/content/competition_package/logs/slim')\n",
    "sz = os.path.getsize('/content/baseline_match_kill_test.zip') / 1e6\n",
    "print(f'\\nbaseline_match_kill_test.zip: {sz:.1f}MB')\n",
    "\n",
    "# Save to Drive\n",
    "shutil.copy('/content/baseline_match_kill_test.zip',\n",
    "            '/content/drive/MyDrive/wunderfund/baseline_match_kill_test.zip')\n",
    "print('Saved to Drive: MyDrive/wunderfund/baseline_match_kill_test.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
