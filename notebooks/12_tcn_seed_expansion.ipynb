{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# TCN Seed Expansion (Colab)\n",
    "Trains 8 base TCN seeds (s47-54) + 5 k=5 alt-config seeds (s42-46).\n",
    "Existing: 5 base TCN seeds (s42-46, mean 0.2650, best s45=0.2688).\n",
    "\n",
    "**Runtime**: Use GPU (T4). High-RAM not needed (TCN is tiny, 9K params)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Mount Drive, download data from Kaggle\n",
    "import os, json\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "os.makedirs('/content/drive/MyDrive/wunderfund', exist_ok=True)\n",
    "\n",
    "!pip install -q kaggle==1.6.14 --force-reinstall\n",
    "os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
    "    json.dump({\"username\": \"vincentvdo6\", \"key\": \"KGAT_17c43012d9e77edf2c183a25acb1489b\"}, f)\n",
    "os.chmod('/root/.kaggle/kaggle.json', 0o600)\n",
    "\n",
    "os.makedirs('/content/data', exist_ok=True)\n",
    "!kaggle datasets download -d vincentvdo6/wunderfund-predictorium -p /content/data/ --force\n",
    "!unzip -o -q /content/data/wunderfund-predictorium.zip -d /content/data/\n",
    "!ls /content/data/*.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-repo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Clone repo, link data, create k5 config if missing\n",
    "import os, subprocess\n",
    "REPO = \"/content/competition_package\"\n",
    "\n",
    "os.chdir(\"/content\")\n",
    "os.system(f\"rm -rf {REPO}\")\n",
    "os.system(f\"git clone https://github.com/vincentvdo6/competition_package.git {REPO}\")\n",
    "os.chdir(REPO)\n",
    "os.makedirs(\"datasets\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "os.system('ln -sf /content/data/train.parquet datasets/train.parquet')\n",
    "os.system('ln -sf /content/data/valid.parquet datasets/valid.parquet')\n",
    "\n",
    "assert os.path.exists(\"datasets/train.parquet\"), \"train.parquet not found!\"\n",
    "assert os.path.exists(\"datasets/valid.parquet\"), \"valid.parquet not found!\"\n",
    "print(\"Commit:\", subprocess.check_output([\"git\", \"rev-parse\", \"--short\", \"HEAD\"], text=True).strip())\n",
    "print(f\"GPU: {os.popen('nvidia-smi --query-gpu=name --format=csv,noheader').read().strip()}\")\n",
    "\n",
    "# Write tcn_k5_v1.yaml if not in repo yet\n",
    "k5_config = os.path.join(REPO, \"configs\", \"tcn_k5_v1.yaml\")\n",
    "if not os.path.exists(k5_config):\n",
    "    print(\"tcn_k5_v1.yaml not in repo, creating...\")\n",
    "    with open(k5_config, \"w\") as f:\n",
    "        f.write(\"\"\"# TCN variant \\u2014 wider kernel for longer receptive field\\n# kernel_size=5, receptive field 253 steps (vs 127 for k=3). ~9K params.\\n\\nmodel:\\n  type: tcn\\n  input_size: 42\\n  hidden_channels: 32\\n  kernel_size: 5\\n  dilations: [1, 2, 4, 8, 16, 32]\\n  dropout: 0.15\\n  output_size: 2\\n\\ntraining:\\n  lr: 0.001\\n  weight_decay: 1e-4\\n  epochs: 50\\n  batch_size: 192\\n  gradient_clip: 1.0\\n  early_stopping_patience: 10\\n  loss: combined\\n  weighted_ratio: 0.62\\n  use_amp: true\\n  scheduler:\\n    type: reduce_on_plateau\\n    factor: 0.5\\n    patience: 5\\n    min_lr: 1e-6\\n\\ndata:\\n  train_path: datasets/train.parquet\\n  valid_path: datasets/valid.parquet\\n  normalize: true\\n  derived_features: true\\n\\nevaluation:\\n  clip_predictions: true\\n  clip_range: [-6, 6]\\n\\nlogging:\\n  log_dir: logs\\n  save_every: 5\\n\"\"\")\n",
    "    print(\"Created tcn_k5_v1.yaml\")\n",
    "else:\n",
    "    print(\"tcn_k5_v1.yaml already in repo\")\n",
    "\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tcn-base-expansion",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: tcn_base_v1 seeds 47-54 (8 new same-config seeds)\n# Existing: s42-46 (5 seeds, mean 0.2650, best s45=0.2688)\n# TCN trains fast (~2 min/seed on T4), total ~16 min\nimport os, subprocess, sys, time, torch\nos.chdir(\"/content/competition_package\")\n\n# Verify GPU first\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    device = \"cuda\"\nelse:\n    print(\"WARNING: CUDA not available, falling back to CPU (slower but OK for 9K params)\")\n    device = \"cpu\"\n\nfor seed in range(47, 55):\n    print(f\"\\n{'='*60}\")\n    print(f\"Training tcn_base_v1 seed {seed}\")\n    print(f\"{'='*60}\", flush=True)\n    t0 = time.time()\n    proc = subprocess.Popen(\n        [sys.executable, \"-u\", \"scripts/train.py\",\n         \"--config\", \"configs/tcn_base_v1.yaml\",\n         \"--seed\", str(seed), \"--device\", device],\n        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n        text=True, bufsize=1\n    )\n    for line in proc.stdout:\n        print(line, end=\"\", flush=True)\n    proc.wait()\n    elapsed = time.time() - t0\n    if proc.returncode != 0:\n        print(f\"ERROR: seed {seed} failed with return code {proc.returncode}\")\n    else:\n        print(f\"Seed {seed} done in {elapsed:.0f}s\")\n\nprint(\"\\ntcn_base_v1 expansion done: seeds 47-54\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tcn-k5-pilot",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: tcn_k5_v1 seeds 42-46 (5 seeds of alt config, wider kernel)\n# New config: kernel_size=5, receptive field 253 steps (vs 127 for k=3)\n# Same params (~9K), same speed. Different temporal reach = diversity.\n# Kill rule: mean val < 0.2400 = kill. > 0.2500 = viable.\nimport os, subprocess, sys, time, torch\nos.chdir(\"/content/competition_package\")\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")\n\nfor seed in range(42, 47):\n    print(f\"\\n{'='*60}\")\n    print(f\"Training tcn_k5_v1 seed {seed}\")\n    print(f\"{'='*60}\", flush=True)\n    t0 = time.time()\n    proc = subprocess.Popen(\n        [sys.executable, \"-u\", \"scripts/train.py\",\n         \"--config\", \"configs/tcn_k5_v1.yaml\",\n         \"--seed\", str(seed), \"--device\", device],\n        stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n        text=True, bufsize=1\n    )\n    for line in proc.stdout:\n        print(line, end=\"\", flush=True)\n    proc.wait()\n    elapsed = time.time() - t0\n    if proc.returncode != 0:\n        print(f\"ERROR: seed {seed} failed with return code {proc.returncode}\")\n    else:\n        print(f\"Seed {seed} done in {elapsed:.0f}s\")\n\nprint(\"\\ntcn_k5_v1 pilot done: seeds 42-46\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Compare all TCN val scores\n",
    "import os, glob, torch\n",
    "os.chdir(\"/content/competition_package\")\n",
    "\n",
    "results = []\n",
    "for pt in sorted(glob.glob(\"logs/*.pt\")):\n",
    "    try:\n",
    "        ckpt = torch.load(pt, map_location=\"cpu\", weights_only=False)\n",
    "    except TypeError:\n",
    "        ckpt = torch.load(pt, map_location=\"cpu\")\n",
    "    score = ckpt.get(\"best_score\", ckpt.get(\"val_score\", None))\n",
    "    name = os.path.basename(pt)\n",
    "    if isinstance(score, (int, float)):\n",
    "        results.append((name, float(score)))\n",
    "    else:\n",
    "        results.append((name, 0.0))\n",
    "\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"{'Rank':<5} {'Model':<55} {'Val Score':>10}\")\n",
    "print(\"-\" * 72)\n",
    "for i, (name, score) in enumerate(results, 1):\n",
    "    print(f\"{i:<5} {name:<55} {score:>10.4f}\")\n",
    "\n",
    "# Summary per config\n",
    "base = [(n, s) for n, s in results if \"tcn_base\" in n]\n",
    "k5 = [(n, s) for n, s in results if \"tcn_k5\" in n]\n",
    "\n",
    "for label, group in [(\"tcn_base_v1 (k=3)\", base), (\"tcn_k5_v1 (k=5)\", k5)]:\n",
    "    if not group:\n",
    "        continue\n",
    "    scores = [s for _, s in group]\n",
    "    mean = sum(scores) / len(scores)\n",
    "    std = (sum((s - mean) ** 2 for s in scores) / len(scores)) ** 0.5\n",
    "    print(f\"\\n--- {label}: {len(group)} seeds ---\")\n",
    "    print(f\"  Mean: {mean:.4f}, Std: {std:.4f}\")\n",
    "    print(f\"  Best: {max(scores):.4f}, Worst: {min(scores):.4f}\")\n",
    "    if mean > 0.2500:\n",
    "        print(f\"  VERDICT: VIABLE for ensemble\")\n",
    "    elif mean > 0.2400:\n",
    "        print(f\"  VERDICT: MARGINAL\")\n",
    "    else:\n",
    "        print(f\"  VERDICT: KILL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strip-zip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Strip checkpoints + zip + save to Drive\n",
    "import os, torch, glob, shutil\n",
    "os.chdir(\"/content/competition_package\")\n",
    "os.makedirs(\"logs/slim\", exist_ok=True)\n",
    "\n",
    "for pt in sorted(glob.glob(\"logs/*.pt\")):\n",
    "    try:\n",
    "        ckpt = torch.load(pt, map_location=\"cpu\", weights_only=False)\n",
    "    except TypeError:\n",
    "        ckpt = torch.load(pt, map_location=\"cpu\")\n",
    "    slim = {\n",
    "        \"model_state_dict\": ckpt[\"model_state_dict\"],\n",
    "        \"config\": ckpt.get(\"config\", {}),\n",
    "        \"best_score\": ckpt.get(\"best_score\", None),\n",
    "    }\n",
    "    out = f\"logs/slim/{os.path.basename(pt)}\"\n",
    "    torch.save(slim, out)\n",
    "    orig = os.path.getsize(pt) / 1e6\n",
    "    new = os.path.getsize(out) / 1e6\n",
    "    print(f\"{os.path.basename(pt)}: {orig:.1f}MB -> {new:.1f}MB\")\n",
    "\n",
    "for npz in sorted(glob.glob(\"logs/normalizer_*.npz\")):\n",
    "    shutil.copy(npz, f\"logs/slim/{os.path.basename(npz)}\")\n",
    "    print(f\"Copied {os.path.basename(npz)}\")\n",
    "\n",
    "print(f\"\\n--- logs/slim/ contents ({len(os.listdir('logs/slim'))} files) ---\")\n",
    "for f in sorted(os.listdir(\"logs/slim\")):\n",
    "    sz = os.path.getsize(f\"logs/slim/{f}\") / 1e6\n",
    "    print(f\"  {f}: {sz:.1f}MB\")\n",
    "\n",
    "# Zip\n",
    "shutil.make_archive(\"/content/tcn_expansion\", \"zip\",\n",
    "                     \"/content/competition_package/logs/slim\")\n",
    "sz = os.path.getsize(\"/content/tcn_expansion.zip\") / 1e6\n",
    "print(f\"\\ntcn_expansion.zip: {sz:.1f}MB\")\n",
    "\n",
    "# Save to Drive\n",
    "shutil.copy(\"/content/tcn_expansion.zip\", \"/content/drive/MyDrive/wunderfund/tcn_expansion.zip\")\n",
    "print(\"Saved to Drive: MyDrive/wunderfund/tcn_expansion.zip\")\n",
    "\n",
    "# Also download directly\n",
    "from google.colab import files\n",
    "files.download(\"/content/tcn_expansion.zip\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}