{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixup Kill Test\n",
    "**Goal**: Train vanilla GRU h=64 with sequence-level Mixup augmentation.\n",
    "\n",
    "Mixup interpolates pairs of training sequences and their targets:\n",
    "- `x' = lam*x_i + (1-lam)*x_j`, `y' = lam*y_i + (1-lam)*y_j`\n",
    "- `lam ~ Beta(0.2, 0.2)`, applied with prob=0.25, annealed off in last 25% epochs\n",
    "- Architecture and inference are IDENTICAL to base parity_v1\n",
    "\n",
    "**Kill test**: 3 seeds (s42, s43, s44). Compare val avg vs base parity_v1 mean (0.2689).\n",
    "- **Kill**: mean val avg < 0.2680\n",
    "- **Scale up**: mean val avg > 0.2720\n",
    "- **Base scores**: s42=0.2649, s43=0.2737, s44=0.2690"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Mount Drive, download data from Kaggle\n",
    "import os, json\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "os.makedirs('/content/drive/MyDrive/wunderfund', exist_ok=True)\n",
    "\n",
    "!pip install -q kaggle==1.6.14 --force-reinstall\n",
    "os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
    "    json.dump({\"username\": \"vincentvdo6\", \"key\": \"FILL_IN\"}, f)\n",
    "os.chmod('/root/.kaggle/kaggle.json', 0o600)\n",
    "\n",
    "os.makedirs('/content/data', exist_ok=True)\n",
    "!kaggle datasets download -d vincentvdo6/wunderfund-predictorium -p /content/data/ --force\n",
    "!unzip -o -q /content/data/wunderfund-predictorium.zip -d /content/data/\n",
    "!ls /content/data/*.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup -- clone repo, link data\n",
    "import os, subprocess\n",
    "REPO = \"/content/competition_package\"\n",
    "\n",
    "os.chdir(\"/content\")\n",
    "subprocess.run([\"rm\", \"-rf\", REPO], check=False)\n",
    "subprocess.run([\"git\", \"clone\", \"https://github.com/vincentvdo6/competition_package.git\", REPO], check=True)\n",
    "os.chdir(REPO)\n",
    "os.makedirs(\"datasets\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "subprocess.run([\"ln\", \"-sf\", \"/content/data/train.parquet\", \"datasets/train.parquet\"], check=True)\n",
    "subprocess.run([\"ln\", \"-sf\", \"/content/data/valid.parquet\", \"datasets/valid.parquet\"], check=True)\n",
    "\n",
    "assert os.path.exists(\"datasets/train.parquet\"), \"train.parquet not found!\"\n",
    "assert os.path.exists(\"datasets/valid.parquet\"), \"valid.parquet not found!\"\n",
    "commit = subprocess.check_output([\"git\", \"rev-parse\", \"--short\", \"HEAD\"], text=True).strip()\n",
    "print(f\"Commit: {commit}\")\n",
    "print(f\"GPU: {subprocess.check_output(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'], text=True).strip()}\")\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Train Mixup kill test (3 seeds)\n",
    "import os, subprocess, sys\n",
    "os.chdir(\"/content/competition_package\")\n",
    "\n",
    "CONFIG = \"configs/gru_parity_v1_mixup.yaml\"\n",
    "SEEDS = [42, 43, 44]\n",
    "\n",
    "print(\"=== MIXUP KILL TEST ===\")\n",
    "print(f\"Config: {CONFIG}\")\n",
    "print(f\"Seeds: {SEEDS}\")\n",
    "print(\"=\" * 60, flush=True)\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training mixup seed {seed}\")\n",
    "    print(f\"{'='*60}\", flush=True)\n",
    "    proc = subprocess.Popen(\n",
    "        [sys.executable, \"-u\", \"scripts/train.py\",\n",
    "         \"--config\", CONFIG,\n",
    "         \"--seed\", str(seed), \"--device\", \"cuda\"],\n",
    "        stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True\n",
    "    )\n",
    "    for line in proc.stdout:\n",
    "        print(line, end=\"\", flush=True)\n",
    "    proc.wait()\n",
    "    if proc.returncode != 0:\n",
    "        print(f\"ERROR: seed {seed} failed with rc={proc.returncode}\")\n",
    "\n",
    "print(f\"\\nAll training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Evaluate Mixup vs base\n",
    "import os, glob, torch\n",
    "os.chdir(\"/content/competition_package\")\n",
    "\n",
    "BASE_SCORES = {42: 0.2649, 43: 0.2737, 44: 0.2690}\n",
    "BASE_MEAN = 0.2689\n",
    "\n",
    "# Collect mixup results\n",
    "mixup_scores = []\n",
    "for pt in sorted(glob.glob(\"logs/gru_parity_v1_mixup_seed*.pt\")):\n",
    "    basename = os.path.basename(pt)\n",
    "    if '_epoch' in basename:\n",
    "        continue\n",
    "    ckpt = torch.load(pt, map_location=\"cpu\", weights_only=False)\n",
    "    score = float(ckpt.get(\"best_score\", 0))\n",
    "    epoch = ckpt.get(\"best_epoch\", \"N/A\")\n",
    "    seed = int(basename.split(\"seed\")[1].replace(\".pt\", \"\"))\n",
    "    base = BASE_SCORES.get(seed, 0)\n",
    "    delta = score - base\n",
    "    mixup_scores.append((seed, score, epoch, delta))\n",
    "    print(f\"seed {seed}: val={score:.4f}, epoch={epoch}, base={base:.4f}, delta={delta:+.4f}\")\n",
    "\n",
    "if mixup_scores:\n",
    "    scores = [s[1] for s in mixup_scores]\n",
    "    deltas = [s[3] for s in mixup_scores]\n",
    "    mean_score = sum(scores) / len(scores)\n",
    "    mean_delta = sum(deltas) / len(deltas)\n",
    "    \n",
    "    print(f\"\\n=== KILL TEST RESULT ===\")\n",
    "    print(f\"Mixup mean val:  {mean_score:.4f}\")\n",
    "    print(f\"Base mean val:   {BASE_MEAN:.4f}\")\n",
    "    print(f\"Mean delta:      {mean_delta:+.4f}\")\n",
    "    print(f\"Best:            {max(scores):.4f}\")\n",
    "    print(f\"Worst:           {min(scores):.4f}\")\n",
    "    print(f\"Positive seeds:  {sum(1 for d in deltas if d > 0)}/{len(deltas)}\")\n",
    "    \n",
    "    if mean_score < 0.2680:\n",
    "        print(f\"\\n>>> KILL: mean {mean_score:.4f} < 0.2680 threshold\")\n",
    "    elif mean_score > 0.2720:\n",
    "        print(f\"\\n>>> SCALE UP: mean {mean_score:.4f} > 0.2720 threshold!\")\n",
    "    else:\n",
    "        print(f\"\\n>>> NEUTRAL: mean {mean_score:.4f} in [0.2680, 0.2720]. Consult Codex.\")\n",
    "else:\n",
    "    print(\"No mixup checkpoints found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Strip checkpoints + zip + save to Drive\n",
    "import os, torch, glob, shutil\n",
    "os.chdir(\"/content/competition_package\")\n",
    "os.makedirs(\"logs/slim\", exist_ok=True)\n",
    "\n",
    "for pt in sorted(glob.glob(\"logs/gru_parity_v1_mixup_seed*.pt\")):\n",
    "    basename = os.path.basename(pt)\n",
    "    if '_epoch' in basename:\n",
    "        continue\n",
    "    ckpt = torch.load(pt, map_location=\"cpu\", weights_only=False)\n",
    "    slim = {\n",
    "        \"model_state_dict\": ckpt[\"model_state_dict\"],\n",
    "        \"config\": ckpt.get(\"config\", {}),\n",
    "        \"best_score\": ckpt.get(\"best_score\", None),\n",
    "        \"best_epoch\": ckpt.get(\"best_epoch\", None),\n",
    "    }\n",
    "    out = f\"logs/slim/{basename}\"\n",
    "    torch.save(slim, out)\n",
    "    orig = os.path.getsize(pt) / 1e6\n",
    "    new = os.path.getsize(out) / 1e6\n",
    "    print(f\"{basename}: {orig:.1f}MB -> {new:.1f}MB\")\n",
    "\n",
    "shutil.make_archive(\"/content/mixup_kill_test\", \"zip\",\n",
    "                     \"/content/competition_package/logs/slim\")\n",
    "sz = os.path.getsize(\"/content/mixup_kill_test.zip\") / 1e6\n",
    "print(f\"\\nmixup_kill_test.zip: {sz:.1f}MB\")\n",
    "\n",
    "shutil.copy(\"/content/mixup_kill_test.zip\",\n",
    "            \"/content/drive/MyDrive/wunderfund/mixup_kill_test.zip\")\n",
    "print(\"Saved to Drive: MyDrive/wunderfund/mixup_kill_test.zip\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
