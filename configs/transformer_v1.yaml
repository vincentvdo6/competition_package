# Small Causal Transformer â€” architecture diversity branch
# ~70K params, sinusoidal PE, pre-norm, windowed causal attention.
# Value is ensemble diversity (corr < 0.92 with GRU), not raw score.

model:
  type: transformer
  input_size: 42
  d_model: 64
  nhead: 4
  num_blocks: 2
  dim_feedforward: 128
  window_size: 128
  dropout: 0.15
  output_size: 2

training:
  lr: 0.0005
  weight_decay: 1e-4
  epochs: 50
  batch_size: 256
  gradient_clip: 1.0
  early_stopping_patience: 10
  loss: combined
  weighted_ratio: 0.62
  use_amp: true
  scheduler:
    type: reduce_on_plateau
    factor: 0.5
    patience: 5
    min_lr: 1e-6

data:
  train_path: datasets/train.parquet
  valid_path: datasets/valid.parquet
  normalize: true
  derived_features: true

evaluation:
  clip_predictions: true
  clip_range: [-6, 6]

logging:
  log_dir: logs
  save_every: 5
