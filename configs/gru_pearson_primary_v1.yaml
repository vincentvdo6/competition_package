# GRU + Pearson-primary loss (metric-aligned v2)
# Base: gru_pearson_v1 (same model architecture)
# Changes: pearson_primary loss with asymmetric t0/t1 weighting,
#   Huber stabilizer, and warmup ramp from 0.4 to 0.80 over 3 epochs.
#   Batch size 256 for stable batch-correlation estimation.
#   Epochs 45 to compensate for fewer batches per epoch.

model:
  type: gru
  input_size: 42
  hidden_size: 144
  num_layers: 2
  dropout: 0.22
  output_size: 2

training:
  lr: 0.0005
  weight_decay: 5e-5
  epochs: 45
  batch_size: 256
  gradient_clip: 1.0
  early_stopping_patience: 8
  loss: pearson_primary
  pearson_primary_alpha: 0.80
  warmup_alpha: 0.4
  warmup_epochs: 3
  huber_delta: 1.0
  target_ratio: 0.62
  pearson_eps: 1e-6
  use_amp: true
  scheduler:
    type: reduce_on_plateau
    factor: 0.5
    patience: 3
    min_lr: 1e-6

data:
  train_path: datasets/train.parquet
  valid_path: datasets/valid.parquet
  normalize: true
  derived_features: true

evaluation:
  clip_predictions: true
  clip_range: [-6, 6]

logging:
  log_dir: logs
  save_every: 5
